"""
RAG-based Long-Term Memory (Hippocampus) æ¨¡çµ„
ä½¿ç”¨å‘é‡è³‡æ–™åº«å¯¦ç¾èªç¾©æœç´¢åŠŸèƒ½
"""
import os
import shutil
from pathlib import Path
from dotenv import load_dotenv
from langchain_chroma import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_core.documents import Document

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()


class KnowledgeBase:
    """
    çŸ¥è­˜åº«é¡åˆ¥ï¼Œè² è²¬è«–æ–‡è¨˜æ†¶èˆ‡èªç¾©æœç´¢
    ä½¿ç”¨ Chroma å‘é‡è³‡æ–™åº«å’Œ Google Generative AI Embeddings
    """
    
    def __init__(self):
        """
        åˆå§‹åŒ–çŸ¥è­˜åº«
        - è¨­å®š Google Generative AI Embeddings
        - åˆå§‹åŒ– Chroma å‘é‡è³‡æ–™åº«
        - æŒä¹…åŒ–ç›®éŒ„ï¼š./ares_knowledge_storeï¼ˆèˆ‡ ML è¨˜æ†¶è·¯å¾‘åˆ†é›¢ï¼‰
        - Collection åç¨±ï¼šares_research_archive
        """
        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        self.embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")
        
        # åˆå§‹åŒ–å‘é‡è³‡æ–™åº«
        # persist_directory è¨­ç‚º ./ares_knowledge_storeï¼ˆèˆ‡ brain_memory/ åˆ†é›¢ï¼‰
        # collection_name è¨­ç‚º ares_research_archive
        self.persist_directory = "./ares_knowledge_store"
        self.vector_db = Chroma(
            persist_directory=self.persist_directory,
            embedding_function=self.embeddings,
            collection_name="ares_research_archive"
        )
    
    def memorize(self, papers: list, tag: str = "general"):
        """
        å°‡è«–æ–‡åˆ—è¡¨å­˜å…¥å‘é‡è³‡æ–™åº«
        
        Args:
            papers: è«–æ–‡å­—å…¸åˆ—è¡¨ï¼Œæ¯å€‹å­—å…¸æ‡‰åŒ…å«ï¼š
                - Title: è«–æ–‡æ¨™é¡Œ
                - TLDR: è«–æ–‡æ‘˜è¦
                - Innovation: å‰µæ–°é»
                - Link: è«–æ–‡é€£çµ
                - Score: è©•åˆ†
                - Date: æ—¥æœŸ
            tag: åˆ†é¡æ¨™ç±¤ï¼Œç”¨æ–¼æ¨™è¨˜è«–æ–‡é¡åˆ¥ï¼ˆå¦‚ "AI", "Biology", "PM"ï¼‰ã€‚é è¨­ç‚º "general"ã€‚
        """
        documents = []
        
        for paper in papers:
            # çµ„åˆ page_contentï¼šTitle + TLDR + Innovation
            page_content = f"{paper.get('Title', '')}\n\n{paper.get('TLDR', '')}\n\n{paper.get('Innovation', '')}"
            
            # è¨­å®š metadataï¼šTitle, Link, Score, Date, category
            metadata = {
                'Title': paper.get('Title', ''),
                'Link': paper.get('Link', ''),
                'Score': paper.get('Score', ''),
                'Date': paper.get('Date', ''),
                'category': tag
            }
            
            # å»ºç«‹ Document å°è±¡
            doc = Document(page_content=page_content, metadata=metadata)
            documents.append(doc)
        
        # å­˜å…¥å‘é‡è³‡æ–™åº«
        self.vector_db.add_documents(documents)
        print(f"ğŸ§  [Hippocampus] stored {len(documents)} papers with tag '{tag}'")
    
    def recall(self, query: str, k=3, filter_tag: str = None):
        """
        å¾å‘é‡è³‡æ–™åº«ä¸­é€²è¡Œèªç¾©æœç´¢ï¼Œå¬å›æœ€ç›¸é—œçš„è«–æ–‡
        
        Args:
            query: æŸ¥è©¢å­—ä¸²
            k: è¿”å›æœ€ç›¸é—œçš„ k ç¯‡è«–æ–‡ï¼ˆé è¨­ç‚º 3ï¼‰
            filter_tag: åˆ†é¡æ¨™ç±¤éæ¿¾å™¨ã€‚å¦‚æœæä¾›ï¼Œåªæœç´¢è©²æ¨™ç±¤çš„è«–æ–‡ï¼ˆå¦‚ "AI", "Biology", "PM"ï¼‰ã€‚
                        å¦‚æœç‚º Noneï¼Œå‰‡æœç´¢æ•´å€‹çŸ¥è­˜åº«ï¼ˆè·¨é ˜åŸŸæœç´¢ï¼‰ã€‚é è¨­ç‚º Noneã€‚
        
        Returns:
            æœ€ç›¸é—œçš„ k å€‹ Document å°è±¡åˆ—è¡¨
        """
        # æ ¹æ“š filter_tag æ±ºå®šæ˜¯å¦ä½¿ç”¨éæ¿¾å™¨
        if filter_tag is not None:
            # ä½¿ç”¨åˆ†é¡æ¨™ç±¤éæ¿¾å™¨é€²è¡Œæœç´¢
            results = self.vector_db.similarity_search(
                query, 
                k=k, 
                filter={"category": filter_tag}
            )
        else:
            # æœç´¢æ•´å€‹çŸ¥è­˜åº«ï¼ˆè·¨é ˜åŸŸæœç´¢ï¼‰
            results = self.vector_db.similarity_search(query, k=k)
        
        return results
    
    def clear(self):
        """
        æ¸…é™¤æ‰€æœ‰å·²å­˜å„²çš„è«–æ–‡è¨˜æ†¶
        
        è­¦å‘Šï¼šæ­¤æ“ä½œä¸å¯é€†ï¼Œå°‡åˆªé™¤æ‰€æœ‰å·²å­˜å„²çš„è«–æ–‡è³‡æ–™
        """
        try:
            # æ–¹æ³• 1: å˜—è©¦ä½¿ç”¨ Chroma çš„ reset_collection æ–¹æ³•ï¼ˆæ¨è–¦ï¼‰
            # é€™æœƒåˆªé™¤é›†åˆä¸¦é‡æ–°å‰µå»ºä¸€å€‹ç©ºçš„
            if hasattr(self.vector_db, 'reset_collection'):
                try:
                    self.vector_db.reset_collection()
                    print(f"ğŸ§  [Hippocampus] å·²æ¸…é™¤æ‰€æœ‰è«–æ–‡è¨˜æ†¶ï¼ˆä½¿ç”¨ reset_collectionï¼‰")
                    return True
                except Exception as reset_error:
                    print(f"âš ï¸  [Hippocampus] reset_collection å¤±æ•—ï¼Œå˜—è©¦å…¶ä»–æ–¹æ³•ï¼š{str(reset_error)}")
            
            # æ–¹æ³• 2: å˜—è©¦ä½¿ç”¨ delete_collectionï¼Œç„¶å¾Œé‡æ–°å‰µå»º
            if hasattr(self.vector_db, 'delete_collection'):
                try:
                    self.vector_db.delete_collection()
                    # é‡æ–°åˆå§‹åŒ–ç©ºçš„è³‡æ–™åº«
                    self.vector_db = Chroma(
                        persist_directory=self.persist_directory,
                        embedding_function=self.embeddings,
                        collection_name="ares_research_archive"
                    )
                    print(f"ğŸ§  [Hippocampus] å·²æ¸…é™¤æ‰€æœ‰è«–æ–‡è¨˜æ†¶ï¼ˆä½¿ç”¨ delete_collectionï¼‰")
                    return True
                except Exception as delete_error:
                    print(f"âš ï¸  [Hippocampus] delete_collection å¤±æ•—ï¼Œå˜—è©¦æ‰‹å‹•åˆªé™¤ï¼š{str(delete_error)}")
            
            # æ–¹æ³• 3: å¦‚æœ API æ–¹æ³•éƒ½å¤±æ•—ï¼Œæ‰‹å‹•åˆªé™¤ç›®éŒ„ä¸¦é‡æ–°åˆå§‹åŒ–
            # æ³¨æ„ï¼šé€™éœ€è¦å…ˆç¢ºä¿æ²’æœ‰å…¶ä»–é€£æ¥åœ¨ä½¿ç”¨è³‡æ–™åº«
            try:
                db_path = Path(self.persist_directory)
                if db_path.exists():
                    # å…ˆå˜—è©¦é—œé–‰é€£æ¥
                    if hasattr(self.vector_db, '_client'):
                        try:
                            self.vector_db._client = None
                        except:
                            pass
                    
                    # åˆªé™¤ç›®éŒ„
                    shutil.rmtree(db_path)
                    print(f"ğŸ§  [Hippocampus] å·²æ¸…é™¤æ‰€æœ‰è«–æ–‡è¨˜æ†¶ï¼ˆæ‰‹å‹•åˆªé™¤ç›®éŒ„ï¼‰")
                    
                    # é‡æ–°åˆå§‹åŒ–ç©ºçš„è³‡æ–™åº«
                    self.vector_db = Chroma(
                        persist_directory=self.persist_directory,
                        embedding_function=self.embeddings,
                        collection_name="ares_research_archive"
                    )
                    return True
                else:
                    print(f"â„¹ï¸  [Hippocampus] è³‡æ–™åº«ä¸å­˜åœ¨ï¼Œç„¡éœ€æ¸…é™¤")
                    return True
            except Exception as manual_error:
                print(f"âŒ [Hippocampus] æ‰‹å‹•æ¸…é™¤å¤±æ•—ï¼š{str(manual_error)}")
                return False
                
        except Exception as e:
            print(f"âŒ [Hippocampus] æ¸…é™¤è³‡æ–™åº«æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
            import traceback
            print(f"   è©³ç´°éŒ¯èª¤ï¼š{traceback.format_exc()}")
            return False
