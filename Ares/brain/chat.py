"""
Ares èŠå¤©æ©Ÿå™¨äººæ¨¡çµ„

æ•´åˆå¤§è…¦è¨˜æ†¶åº«ï¼ˆHippocampusï¼‰èˆ‡ LLMï¼Œå¯¦ç¾åŸºæ–¼çŸ¥è­˜åº«çš„å•ç­”åŠŸèƒ½
"""
import os
import re
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from Ares.brain.memory import KnowledgeBase

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()


class AresChatbot:
    """
    Ares èŠå¤©æ©Ÿå™¨äºº - æ•´åˆé•·æœŸè¨˜æ†¶èˆ‡ LLM çš„æ™ºèƒ½åŠ©æ‰‹
    
    ä½¿ç”¨å‘é‡è³‡æ–™åº«æª¢ç´¢ç›¸é—œè«–æ–‡ï¼Œä¸¦çµåˆ LLM ç”Ÿæˆå›ç­”
    """
    
    def __init__(self):
        """
        åˆå§‹åŒ–èŠå¤©æ©Ÿå™¨äºº
        
        - åˆå§‹åŒ–å¤§è…¦è¨˜æ†¶åº«ï¼ˆKnowledgeBaseï¼‰ä½œç‚ºé•·æœŸè¨˜æ†¶
        - åˆå§‹åŒ– LLMï¼ˆChatGoogleGenerativeAIï¼‰ä½œç‚ºèªéŸ³è¼¸å‡º
        
        Raises:
            ValueError: å¦‚æœç’°å¢ƒè®Šæ•¸ä¸­ç¼ºå°‘ GEMINI_API_KEYã€‚
        """
        # è¼‰å…¥ç’°å¢ƒè®Šæ•¸
        load_dotenv()
        
        # å¾ç’°å¢ƒè®Šæ•¸å–å¾— API é‡‘é‘°
        api_key = os.getenv('GEMINI_API_KEY')
        
        if not api_key:
            raise ValueError('éŒ¯èª¤ï¼šç’°å¢ƒè®Šæ•¸ä¸­ç¼ºå°‘ GEMINI_API_KEYï¼Œè«‹åœ¨ .env æª”æ¡ˆä¸­è¨­å®šã€‚')
        
        # å¤§è…¦è¨˜æ†¶åº«ï¼ˆé•·æœŸè¨˜æ†¶ï¼‰
        self.brain = KnowledgeBase()
        
        # LLMï¼ˆèªéŸ³è¼¸å‡ºï¼‰
        # ä½¿ç”¨ gemini-flash-latestï¼Œèˆ‡å…¶ä»–æ¨¡çµ„ä¿æŒä¸€è‡´
        self.llm = ChatGoogleGenerativeAI(
            model="models/gemini-flash-latest",
            temperature=0.7,
            google_api_key=api_key
        )
    
    def chat(self, user_query: str, filter_tag: str = None):
        """
        èˆ‡ç”¨æˆ¶å°è©±ï¼ŒåŸºæ–¼çŸ¥è­˜åº«å›ç­”å•é¡Œ
        
        Args:
            user_query: ç”¨æˆ¶çš„å•é¡Œ
            filter_tag: å¯é¸çš„åˆ†é¡æ¨™ç±¤éæ¿¾å™¨ï¼Œç”¨æ–¼é™åˆ¶æœç´¢ç¯„åœ
        
        Returns:
            str: LLM ç”Ÿæˆçš„å›ç­”ï¼ˆç¹é«”ä¸­æ–‡ï¼‰
        """
        # æ­¥é©Ÿ 1: Recall - å¾è¨˜æ†¶åº«ä¸­æª¢ç´¢ç›¸é—œè«–æ–‡
        memories = self.brain.recall(user_query, k=3, filter_tag=filter_tag)
        
        # æ­¥é©Ÿ 2: Context Construction - æ§‹å»ºä¸Šä¸‹æ–‡
        if not memories:
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°ä»»ä½•è¨˜æ†¶ï¼Œè¿”å›æç¤ºè¨Šæ¯
            return "æˆ‘è…¦ä¸­æ²’æœ‰ç›¸é—œè¨˜æ†¶ï¼Œè«‹å…ˆæ´¾æˆ‘å» Research æŠ“å–è³‡æ–™ã€‚"
        
        # å°‡æª¢ç´¢åˆ°çš„æ–‡ä»¶å…§å®¹çµ„åˆæˆä¸Šä¸‹æ–‡å­—ä¸²ï¼Œä¸¦ä¿å­˜å¼•ç”¨è³‡è¨Š
        context_parts = []
        references = []  # ç”¨æ–¼ä¿å­˜å¼•ç”¨è³‡è¨Š
        
        for i, doc in enumerate(memories, 1):
            title = doc.metadata.get('Title', 'æœªçŸ¥æ¨™é¡Œ')
            link = doc.metadata.get('Link', '')
            content = doc.page_content
            # å°‡å…§å®¹åˆ†æ®µï¼Œä»¥ä¾¿å¾ŒçºŒæ¨™è¨»å…·é«”æ®µè½
            content_lines = content.split('\n')
            context_parts.append(f"[è«–æ–‡ {i}] {title}\n{content}")
            
            # ä¿å­˜å¼•ç”¨è³‡è¨Š
            references.append({
                'id': i,
                'title': title,
                'link': link,
                'content': content,
                'content_lines': content_lines
            })
        
        context_str = "\n\n".join(context_parts)
        
        # æ­¥é©Ÿ 3: Prompting - å‰µå»ºæç¤ºè©
        prompt = f"""è«‹æ ¹æ“šä»¥ä¸‹æª¢ç´¢åˆ°çš„è«–æ–‡å…§å®¹ç›´æ¥å›ç­”ç”¨æˆ¶çš„å•é¡Œã€‚

**å›ç­”æ ¼å¼è¦æ±‚ï¼š**
1. ç›´æ¥å›ç­”å•é¡Œï¼Œä¸è¦è‡ªæˆ‘ä»‹ç´¹æˆ–é–‹å ´ç™½
2. å›ç­”é–‹é ­æ‡‰è©²æ˜¯ã€Œæ ¹æ“šè¨˜æ†¶åº«ä¸­çš„è³‡æ–™ã€æˆ–ã€Œæ ¹æ“šæª¢ç´¢åˆ°çš„è«–æ–‡ã€
3. å›ç­”ä¸­çš„æ¯ä¸€å€‹çµè«–æˆ–äº‹å¯¦éƒ½å¿…é ˆä½¿ç”¨å¼•ç”¨æ ¼å¼ [è«–æ–‡ç·¨è™Ÿ]ï¼Œä¾‹å¦‚ [1]ã€[2] ç­‰
4. å¦‚æœæŸå€‹çµè«–ä¾†è‡ªå¤šç¯‡è«–æ–‡ï¼Œè«‹ä½¿ç”¨ [1,2] çš„æ ¼å¼
5. è«‹å‹™å¿…ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œé¿å…ä½¿ç”¨ç°¡é«”ä¸­æ–‡æˆ–è‹±æ–‡
6. å¦‚æœç­”æ¡ˆä¸åœ¨ä¸Šä¸‹æ–‡ä¸­ï¼Œè«‹æ˜ç¢ºèªªæ˜ã€Œæ ¹æ“šè¨˜æ†¶åº«ä¸­çš„è³‡æ–™ï¼Œæˆ‘ç„¡æ³•æ‰¾åˆ°ç›¸é—œè³‡è¨Šã€

ä¸Šä¸‹æ–‡å…§å®¹ï¼ˆä¾†è‡ªè¨˜æ†¶åº«ï¼‰ï¼š
{context_str}

å•é¡Œï¼š{user_query}

è«‹ç›´æ¥å›ç­”å•é¡Œï¼ˆä¸è¦èªªã€Œæˆ‘æ˜¯ Aresã€æˆ–é¡ä¼¼é–‹å ´ç™½ï¼‰ï¼š"""
        
        # æ­¥é©Ÿ 4: Generate - èª¿ç”¨ LLM ç”Ÿæˆå›ç­”
        try:
            response = self.llm.invoke(prompt)
            
            # æå–å›æ‡‰å…§å®¹ï¼ˆåªæå–ç´”æ–‡å­—ï¼Œå®Œå…¨å¿½ç•¥æŠ€è¡“ç´°ç¯€ï¼‰
            response_text = None
            
            # æƒ…æ³ 1: å›æ‡‰æ˜¯åˆ—è¡¨æ ¼å¼ [{'type': 'text', 'text': '...', 'extras': {...}}]
            # é€™æ˜¯æœ€å¸¸è¦‹çš„æ ¼å¼ï¼Œå„ªå…ˆè™•ç†
            if isinstance(response, list) and len(response) > 0:
                # éæ­·åˆ—è¡¨ï¼Œå°‹æ‰¾åŒ…å« 'text' çš„å­—å…¸
                for item in response:
                    if isinstance(item, dict):
                        # åªæå– 'text' æ¬„ä½ï¼Œå®Œå…¨å¿½ç•¥ 'extras'ã€'type' ç­‰å…¶ä»–æ¬„ä½
                        text_value = item.get('text')
                        if text_value is not None:
                            # å¦‚æœ text_value æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨ï¼ˆé€™æ˜¯æˆ‘å€‘æƒ³è¦çš„ï¼‰
                            if isinstance(text_value, str):
                                response_text = text_value
                                break
                            # å¦‚æœ text_value æ˜¯å…¶ä»–é¡å‹ï¼Œè½‰ç‚ºå­—ç¬¦ä¸²
                            elif text_value:
                                response_text = str(text_value)
                                break
                    # å¦‚æœåˆ—è¡¨å…ƒç´ æœ‰ content æˆ– text å±¬æ€§
                    elif hasattr(item, 'content'):
                        content = item.content
                        # å¦‚æœ content æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨
                        if isinstance(content, str):
                            response_text = content
                            break
                        # å¦‚æœ content æ˜¯åˆ—è¡¨ï¼Œéè¿´è™•ç†
                        elif isinstance(content, list) and len(content) > 0:
                            for sub_item in content:
                                if isinstance(sub_item, dict) and 'text' in sub_item:
                                    response_text = sub_item['text']
                                    break
                            if response_text:
                                break
                    elif hasattr(item, 'text'):
                        text_attr = item.text
                        if isinstance(text_attr, str):
                            response_text = text_attr
                            break
                
                # å¦‚æœåˆ—è¡¨è™•ç†å¾Œä»æ²’æœ‰æ‰¾åˆ°æ–‡å­—ï¼Œå˜—è©¦ç¬¬ä¸€å€‹å…ƒç´ çš„å…¶ä»–å±¬æ€§
                if not response_text and len(response) > 0:
                    first_item = response[0]
                    if hasattr(first_item, 'content'):
                        content = first_item.content
                        if isinstance(content, str):
                            response_text = content
                        elif isinstance(content, list) and len(content) > 0:
                            for sub_item in content:
                                if isinstance(sub_item, dict) and 'text' in sub_item:
                                    response_text = sub_item['text']
                                    break
                    elif hasattr(first_item, 'text'):
                        response_text = first_item.text
                    # æœ€å¾Œæ‰‹æ®µï¼šè½‰ç‚ºå­—ç¬¦ä¸²ï¼ˆä½†é€™ä¸æ‡‰è©²ç™¼ç”Ÿï¼‰
                    if not response_text:
                        response_text = "ç„¡æ³•è§£æå›æ‡‰æ ¼å¼"
            
            # æƒ…æ³ 2: å›æ‡‰æœ‰ content å±¬æ€§
            elif hasattr(response, 'content'):
                content = response.content
                # å¦‚æœ content æ˜¯åˆ—è¡¨ï¼Œéè¿´è™•ç†
                if isinstance(content, list) and len(content) > 0:
                    for item in content:
                        if isinstance(item, dict) and 'text' in item:
                            response_text = item['text']
                            break
                        elif isinstance(item, str):
                            response_text = item
                            break
                # å¦‚æœ content æ˜¯å­—å…¸ï¼Œæå– text
                elif isinstance(content, dict):
                    response_text = content.get('text')
                # å¦‚æœ content æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨
                elif isinstance(content, str):
                    response_text = content
                else:
                    response_text = str(content)
            
            # æƒ…æ³ 3: å›æ‡‰æœ‰ text å±¬æ€§
            elif hasattr(response, 'text'):
                response_text = response.text
            
            # æƒ…æ³ 4: å›æ‡‰æ˜¯å­—å…¸æ ¼å¼
            elif isinstance(response, dict):
                # åªæå– 'text' æ¬„ä½ï¼Œå¿½ç•¥å…¶ä»–æ‰€æœ‰æ¬„ä½ï¼ˆåŒ…æ‹¬ 'extras'ï¼‰
                response_text = response.get('text') or response.get('content')
            
            # æƒ…æ³ 5: å›æ‡‰æ˜¯å­—ä¸²
            elif isinstance(response, str):
                response_text = response
            
            # æƒ…æ³ 6: å…¶ä»–æ ¼å¼ï¼Œè½‰ç‚ºå­—ä¸²
            else:
                response_text = str(response)
            
            # ç¢ºä¿æ˜¯å­—ä¸²é¡å‹
            if not isinstance(response_text, str):
                response_text = str(response_text)
            
            # ç‰¹æ®Šè™•ç†ï¼šå¦‚æœ response_text çœ‹èµ·ä¾†åƒæ˜¯å­—å…¸çš„å­—ç¬¦ä¸²è¡¨ç¤ºï¼Œå˜—è©¦æå– text å­—æ®µ
            # é€™è™•ç†é¡ä¼¼ {'type': 'text', 'text': '...', 'extras': {...}} çš„æ ¼å¼
            # ä½†é¦–å…ˆæª¢æŸ¥æ˜¯å¦åŒ…å« 'extras'ï¼Œå¦‚æœåŒ…å«å‰‡èªªæ˜å¯èƒ½æ˜¯æ•´å€‹å­—å…¸çš„å­—ç¬¦ä¸²è¡¨ç¤º
            if response_text and (
                "'extras'" in response_text or 
                '"extras"' in response_text or
                response_text.strip().startswith("{'type':") or 
                response_text.strip().startswith('{"type":') or 
                ("'text'" in response_text and "'extras'" in response_text) or
                ('"text"' in response_text and '"extras"' in response_text)
            ):
                try:
                    import ast
                    # å˜—è©¦è§£æç‚º Python å­—å…¸
                    parsed_dict = ast.literal_eval(response_text)
                    if isinstance(parsed_dict, dict) and 'text' in parsed_dict:
                        response_text = parsed_dict['text']
                        if not isinstance(response_text, str):
                            response_text = str(response_text)
                except (ValueError, SyntaxError):
                    # å¦‚æœ ast.literal_eval å¤±æ•—ï¼Œä½¿ç”¨æ­£å‰‡æå–
                    import re
                    # å„ªå…ˆåŒ¹é…é›™å¼•è™Ÿæ ¼å¼ "text": "..."
                    pattern1 = r'["\']text["\']\s*:\s*"((?:[^"\\]|\\.|\\n)*)"'
                    text_match = re.search(pattern1, response_text, re.DOTALL)
                    
                    if not text_match:
                        # å˜—è©¦åŒ¹é…å–®å¼•è™Ÿæ ¼å¼
                        pattern2 = r'["\']text["\']\s*:\s*\'((?:[^\'\\]|\\.|\\n)*)\''
                        text_match = re.search(pattern2, response_text, re.DOTALL)
                    
                    if not text_match:
                        # å˜—è©¦æ›´å¯¬é¬†çš„æ¨¡å¼ï¼ˆåŒ¹é…åˆ°ç¬¬ä¸€å€‹ 'extras' æˆ–çµå°¾ï¼‰
                        pattern3 = r'["\']text["\']\s*:\s*["\']((?:[^"\']|\\["\']|\\n)+?)(?:["\']\s*,\s*["\']extras["\']|["\']\s*[,}])'
                        text_match = re.search(pattern3, response_text, re.DOTALL)
                    
                    if text_match:
                        response_text = text_match.group(1)
                        # ç§»é™¤å¯èƒ½çš„è½‰ç¾©å­—ç¬¦
                        response_text = response_text.replace('\\n', '\n').replace("\\'", "'").replace('\\"', '"')
            
            # æ¸…ç†å›æ‡‰æ–‡å­—ï¼ˆç§»é™¤å¤šé¤˜çš„ç©ºç™½å’Œæ ¼å¼ï¼‰
            if response_text:
                response_text = response_text.strip()
                
                # ç§»é™¤æˆ–æ›¿æ›ä¸æƒ³è¦çš„é–‹å ´ç™½
                unwanted_prefixes = [
                    "æˆ‘æ˜¯ Aresï¼Œ",
                    "æˆ‘æ˜¯ Ares ",
                    "Ares æ˜¯",
                    "æ ¹æ“šæˆ‘çš„ç†è§£ï¼Œ",
                    "ä½œç‚ºä¸€ä½å…ˆé€²çš„ AI ç ”ç©¶åŠ©ç†ï¼Œ",
                    "ä½œç‚º AI ç ”ç©¶åŠ©ç†ï¼Œ",
                ]
                
                for prefix in unwanted_prefixes:
                    if response_text.startswith(prefix):
                        response_text = response_text[len(prefix):].strip()
                        break
                
                # å¦‚æœå›ç­”é–‹é ­ä¸æ˜¯ã€Œæ ¹æ“šè¨˜æ†¶åº«ã€æˆ–ã€Œæ ¹æ“šæª¢ç´¢ã€ï¼Œæ·»åŠ å‰ç¶´
                if not response_text.startswith(("æ ¹æ“šè¨˜æ†¶åº«", "æ ¹æ“šæª¢ç´¢", "æ ¹æ“šä»¥ä¸‹", "è¨˜æ†¶åº«ä¸­çš„è³‡æ–™")):
                    # æª¢æŸ¥æ˜¯å¦åŒ…å«ã€Œæ ¹æ“šã€é–‹é ­çš„å¥å­ï¼Œå¦‚æœæ²’æœ‰å‰‡æ·»åŠ 
                    if not re.match(r'^æ ¹æ“š', response_text):
                        response_text = "æ ¹æ“šè¨˜æ†¶åº«ä¸­çš„è³‡æ–™ï¼Œ" + response_text
            
            # æœ€çµ‚æª¢æŸ¥ï¼šç¢ºä¿ response_text ä¸åŒ…å«æŠ€è¡“ç´°ç¯€ï¼ˆå¦‚ 'extras'ã€'signature' ç­‰ï¼‰
            if response_text and (
                "'extras'" in response_text or 
                '"extras"' in response_text or
                "'signature'" in response_text or
                '"signature"' in response_text or
                response_text.startswith("[{") or
                response_text.startswith("[{'")
            ):
                # å¦‚æœä»ç„¶åŒ…å«æŠ€è¡“ç´°ç¯€ï¼Œå˜—è©¦æœ€å¾Œä¸€æ¬¡æå–
                import re
                # å˜—è©¦æå–æœ€é•·çš„ç´”æ–‡å­—æ®µè½ï¼ˆä¸åŒ…å«å­—å…¸çµæ§‹ï¼‰
                # åŒ¹é…å¾ 'text': '...' åˆ° 'extras' æˆ–çµå°¾çš„å…§å®¹
                pattern = r'["\']text["\']\s*:\s*["\']((?:[^"\']|\\["\']|\\n)+?)(?:["\']\s*,\s*["\']extras["\']|["\']\s*[,}])'
                text_match = re.search(pattern, response_text, re.DOTALL)
                if text_match:
                    response_text = text_match.group(1)
                    response_text = response_text.replace('\\n', '\n').replace("\\'", "'").replace('\\"', '"').strip()
                else:
                    # å¦‚æœç„¡æ³•æå–ï¼Œè¿”å›éŒ¯èª¤è¨Šæ¯
                    response_text = "æŠ±æ­‰ï¼Œç„¡æ³•è§£æå›æ‡‰æ ¼å¼ã€‚"
            
            # å¦‚æœå›æ‡‰ç‚ºç©ºï¼Œè¿”å›é è¨­è¨Šæ¯
            if not response_text or len(response_text) == 0:
                response_text = "æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•ç”Ÿæˆå›ç­”ã€‚"
            
            # æ­¥é©Ÿ 5: æ·»åŠ åƒè€ƒæ–‡ç»éƒ¨åˆ†
            # è§£æå›ç­”ä¸­çš„å¼•ç”¨ï¼ˆå¦‚ [1], [2], [1,2] ç­‰ï¼‰
            import re
            citation_pattern = r'\[(\d+(?:,\d+)*)\]'
            citations_found = set()
            citation_positions = {}  # è¨˜éŒ„æ¯å€‹å¼•ç”¨åœ¨å›ç­”ä¸­çš„ä½ç½®
            
            for match in re.finditer(citation_pattern, response_text):
                # æå–å¼•ç”¨ç·¨è™Ÿï¼ˆå¦‚ "1", "2", "1,2"ï¼‰
                citation_ids = match.group(1).split(',')
                citation_start = match.start()
                citation_end = match.end()
                
                # æ‰¾åˆ°å¼•ç”¨å‰çš„å¥å­ï¼ˆæœ€å¤šå‰ 200 å­—å…ƒï¼‰
                context_start = max(0, citation_start - 200)
                context_text = response_text[context_start:citation_end]
                
                for cid in citation_ids:
                    try:
                        ref_id = int(cid.strip())
                        citations_found.add(ref_id)
                        if ref_id not in citation_positions:
                            citation_positions[ref_id] = []
                        citation_positions[ref_id].append(context_text)
                    except ValueError:
                        pass
            
            # ç”Ÿæˆåƒè€ƒæ–‡ç»éƒ¨åˆ†
            if citations_found and references:
                response_text += "\n\n" + "=" * 60 + "\n"
                response_text += "ğŸ“š åƒè€ƒæ–‡ç»èˆ‡ä¾†æºæ®µè½\n"
                response_text += "=" * 60 + "\n\n"
                
                for ref_id in sorted(citations_found):
                    if 1 <= ref_id <= len(references):
                        ref = references[ref_id - 1]  # å¼•ç”¨ç·¨è™Ÿå¾ 1 é–‹å§‹
                        response_text += f"[{ref_id}] {ref['title']}\n"
                        if ref['link']:
                            response_text += f"   é€£çµï¼š{ref['link']}\n"
                        
                        # æ‰¾åˆ°å›ç­”ä¸­èˆ‡æ­¤å¼•ç”¨ç›¸é—œçš„å…§å®¹
                        if ref_id in citation_positions:
                            # å¾å›ç­”çš„ä¸Šä¸‹æ–‡ä¸­æå–é—œéµè©ï¼Œåœ¨è«–æ–‡ä¸­æ‰¾åˆ°ç›¸é—œæ®µè½
                            contexts = citation_positions[ref_id]
                            # æå–é—œéµè©ï¼ˆç°¡å–®ç­–ç•¥ï¼šå–ä¸Šä¸‹æ–‡ä¸­çš„åè©å’Œå‹•è©ï¼‰
                            keywords = []
                            for ctx in contexts:
                                # ç§»é™¤å¼•ç”¨æ¨™è¨˜ï¼Œæå–é—œéµè©
                                ctx_clean = re.sub(r'\[\d+(?:,\d+)*\]', '', ctx)
                                # æå–ä¸­æ–‡è©å½™ï¼ˆ2-4 å­—ï¼‰
                                chinese_words = re.findall(r'[\u4e00-\u9fff]{2,4}', ctx_clean)
                                keywords.extend(chinese_words[:5])  # æ¯å€‹ä¸Šä¸‹æ–‡æœ€å¤š 5 å€‹é—œéµè©
                            
                            # åœ¨è«–æ–‡ä¸­æ‰¾åˆ°åŒ…å«é—œéµè©çš„æ®µè½
                            relevant_paragraphs = []
                            content_lines = ref['content_lines']
                            
                            for line in content_lines:
                                if any(keyword in line for keyword in keywords[:3]):  # åªæª¢æŸ¥å‰ 3 å€‹é—œéµè©
                                    if len(line.strip()) > 20:  # åªä¿ç•™æœ‰æ„ç¾©çš„æ®µè½
                                        relevant_paragraphs.append(line.strip())
                                        if len(relevant_paragraphs) >= 2:  # æœ€å¤šé¡¯ç¤º 2 å€‹æ®µè½
                                            break
                            
                            if relevant_paragraphs:
                                response_text += "   ç›¸é—œæ®µè½ï¼š\n"
                                for para in relevant_paragraphs:
                                    # é™åˆ¶æ®µè½é•·åº¦
                                    if len(para) > 300:
                                        para = para[:300] + "..."
                                    response_text += f"   â€¢ {para}\n"
                            else:
                                # å¦‚æœæ‰¾ä¸åˆ°ç›¸é—œæ®µè½ï¼Œé¡¯ç¤ºè«–æ–‡çš„å‰ 200 å­—ä½œç‚ºé è¦½
                                content_preview = ref['content'][:200]
                                if len(ref['content']) > 200:
                                    content_preview += "..."
                                response_text += f"   ç›¸é—œæ®µè½ï¼š{content_preview}\n"
                        else:
                            # å¦‚æœæ²’æœ‰æ‰¾åˆ°å¼•ç”¨ä½ç½®ï¼Œé¡¯ç¤ºè«–æ–‡çš„å‰ 200 å­—
                            content_preview = ref['content'][:200]
                            if len(ref['content']) > 200:
                                content_preview += "..."
                            response_text += f"   ç›¸é—œæ®µè½ï¼š{content_preview}\n"
                        
                        response_text += "\n"
            
            return response_text
            
        except Exception as e:
            # éŒ¯èª¤è™•ç†
            error_msg = f"ç”Ÿæˆå›ç­”æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"
            print(f"[è­¦å‘Š] {error_msg}")
            return f"æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"
